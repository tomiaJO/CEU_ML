---
title: "ML HW1"
subtitle: "subtitle"
author: "Tamas Koncz"
date: '2018-01-21'
output:
  html_document:
    df_print: paged
  html_notebook:
    df_print: paged
---

```{r, message=FALSE}
library(data.table)
library(ggplot2)
library(caret)
library(rpart)

theme_set(theme_bw())   # globally set ggplot theme

set.seed(1234)
```


### 1. Model selection with a validation set (5 points)

### 2. Predicting developer salaries (5 points)

#### a) Describe what the data cleansing steps mean.

Explanations below each code piece:
```{r}
data <- fread("../../data/stackoverflow2017/survey_results_public_selected.csv")
```

Reads in data for the .csv file.

```{r}
data <- data[!is.na(Salary) & Salary > 0]
```

Removes rows, where Salary information is missing (null), or it is below / equals to 0.
Dataset goes from 51392 observations to 12885 - however, this is necessary, so that the model can be trained on meaningful salary information. 

```{r}
data <- data[complete.cases(data)]
```

Removes any rows with missing (null) information in any column.
No impact on the dataset in this case. The step could be used to avoid cases where a model can't handle missing information gracefully.

```{r}
data <- data[, Gender := ifelse(Gender == "Male", "Male",
                              ifelse(Gender == "Female", "Female", "Other"))]
```

In the original dataset, there were 20 different gender codes - the above reduces this to three (by bucketing everything that's not either "Male" or "Female" as "Other").

```{r}
large_countries <- data[, .N, by = "Country"][N > 60][["Country"]]
data <- data[, Country := ifelse(Country %in% large_countries, Country, "Other")]
rm(large_countries)
```

This step is similar to the above - however, here countries with 60 or less observations are categorized as "Other".
(Observation types that are very rare might not be much useful for prediction, hence grouping them can help)

#### b) Using graphs, find at least two interesting features that can contribute to understanding developer salaries.

```{r}
dt_size_mapping <- data.table(unique(data$CompanySize))
dt_size_mapping <- cbind(dt_size_mapping, 
                         data.table(c("10K<", "5K<", "1K<", 
                                 "500<", "10<", "100<", 
                                 "20<", "10>", 
                                 "Other", "Other", "Other" )))
                         
setnames(dt_size_mapping, c("CompanySize", "CompSize"))
data <- merge(data, dt_size_mapping, by = "CompanySize", all.x = TRUE)
rm(dt_size_mapping)

data[, CompSize := factor(CompSize, levels = c("10K<", "5K<", "1K<", "500<", "100<", "20<", "10<", "10>", "Other"))]
```

The above piece of code remaps the "CompanySize" variable to a more readable format for charts, as well as sets the right order level.

```{r}
#data[, .(count = .N, avg = mean(Salary)), by = .(CompanySize, CompSize)][order(CompSize)]

summary <- data[, 
                .(avg_salary = mean(Salary)), 
                by = .(CompSize, Gender)][order(CompSize, Gender)]

ggplot() + 
      geom_point(data = data, aes(x = CompSize, y = Salary), color = "blue", alpha = 0.1) + 
      geom_line(data = summary, aes(x = CompSize, y = avg_salary), color = "orange", size = 1.25, group = 1) +
      geom_text(data = summary, aes(x = CompSize, y = avg_salary, label = round(avg_salary / 1000)), color = "orange", group = 1, hjust = 0, vjust = 0) +
      facet_grid(~Gender)
## TODO: better colors
## TODO: labels, etc.
```

We can observe at least three important things on the above chart:

      1. Generally, all genders are getting better paid the larger the firm size
      2. Visually, the gender gap does not seem significant: all three genders are getting paid similar amount, with similar dynamics (see above point)
      3. There are a lot more males among the observations than either females or "other"

```{r}
str(data)
```


#### c) Create a training and a test set assigning 70% to the training set and 30% as the test set.

#### d) Using caret train at least two predictive models to predict the logarithm of Salary (they can be of the same family but with different hyperparameters or they can be of different families like we used lm and rpart in the first exercise). Make sure NOT to include Salary as a predictor variable. Also, just before calling train, remember to use set.seed.




### 3. Leave-one-out cross validation (3 points)


